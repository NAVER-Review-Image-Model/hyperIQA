{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01539453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd0782ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import folders\n",
    "\n",
    "class DataLoader(object):\n",
    "    \"\"\"Dataset class for IQA databases\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, path, img_indx, patch_size, patch_num, batch_size=1, istrain=True):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.istrain = istrain\n",
    "\n",
    "        if (dataset == 'live') | (dataset == 'csiq') | (dataset == 'tid2013') | (dataset == 'livec'):\n",
    "            # Train transforms\n",
    "            if istrain:\n",
    "                transforms = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.RandomCrop(size=patch_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                     std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "            # Test transforms\n",
    "            else:\n",
    "                transforms = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomCrop(size=patch_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                     std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "        elif dataset == 'koniq-10k':\n",
    "            if istrain:\n",
    "                transforms = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.Resize((512, 384)),\n",
    "                    torchvision.transforms.RandomCrop(size=patch_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                     std=(0.229, 0.224, 0.225))])\n",
    "            else:\n",
    "                transforms = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.Resize((512, 384)),\n",
    "                    torchvision.transforms.RandomCrop(size=patch_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                     std=(0.229, 0.224, 0.225))])\n",
    "        elif dataset == 'bid':\n",
    "            if istrain:\n",
    "                transforms = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.Resize((512, 512)),\n",
    "                    torchvision.transforms.RandomCrop(size=patch_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                     std=(0.229, 0.224, 0.225))])\n",
    "            else:\n",
    "                transforms = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.Resize((512, 512)),\n",
    "                    torchvision.transforms.RandomCrop(size=patch_size),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                     std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "        if dataset == 'live':\n",
    "            self.data = folders.LIVEFolder(\n",
    "                root=path, index=img_indx, transform=transforms, patch_num=patch_num)\n",
    "        elif dataset == 'livec':\n",
    "            self.data = folders.LIVEChallengeFolder(\n",
    "                root=path, index=img_indx, transform=transforms, patch_num=patch_num)\n",
    "        elif dataset == 'csiq':\n",
    "            self.data = folders.CSIQFolder(\n",
    "                root=path, index=img_indx, transform=transforms, patch_num=patch_num)\n",
    "        elif dataset == 'koniq-10k':\n",
    "            self.data = folders.Koniq_10kFolder(\n",
    "                root=path, index=img_indx, transform=transforms, patch_num=patch_num)\n",
    "        elif dataset == 'tid2013':\n",
    "            self.data = folders.TID2013Folder(\n",
    "                root=path, index=img_indx, transform=transforms, patch_num=patch_num)\n",
    "        \n",
    "        elif dataset == 'bid':\n",
    "            self.data = folders.CustomDataSet(\n",
    "                root=path, index=img_indx, transform=transforms, patch_num=patch_num)\n",
    "\n",
    "    def get_data(self):\n",
    "        if self.istrain:\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                self.data, batch_size=self.batch_size, shuffle=True)\n",
    "        else:\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                self.data, batch_size=1, shuffle=False)\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dd00944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = '../Data/train/'\n",
    "# data_test = '../Data/test/'\n",
    "# data_val = '../Data/valid/'\n",
    "\n",
    "# patch_size = 224\n",
    "\n",
    "# transforms = torchvision.transforms.Compose([\n",
    "#                     torchvision.transforms.RandomHorizontalFlip(),\n",
    "#                     torchvision.transforms.Resize((512, 512)),\n",
    "#                     torchvision.transforms.RandomCrop(size=patch_size),\n",
    "#                     torchvision.transforms.ToTensor(),\n",
    "#                     torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "#                                                      std=(0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12383687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import folders\n",
    "\n",
    "# data = folders.CustomDataSet(root=data_train, index=0, transform=transforms, patch_num=25)\n",
    "# data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e068cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class HyperIQASolver(object):\n",
    "    \"\"\"Solver for training and testing hyperIQA\"\"\"\n",
    "    def __init__(self, config, path, train_idx, test_idx):\n",
    "\n",
    "        self.epochs = config.epochs\n",
    "        self.test_patch_num = config.test_patch_num\n",
    "\n",
    "        self.model_hyper = models.HyperNet(16, 112, 224, 112, 56, 28, 14, 7).to(device)\n",
    "        self.model_hyper.train(True)\n",
    "\n",
    "        self.l1_loss = torch.nn.L1Loss().to(device)\n",
    "\n",
    "        backbone_params = list(map(id, self.model_hyper.res.parameters()))\n",
    "        self.hypernet_params = filter(lambda p: id(p) not in backbone_params, self.model_hyper.parameters())\n",
    "        self.lr = config.lr\n",
    "        self.lrratio = config.lr_ratio\n",
    "        self.weight_decay = config.weight_decay\n",
    "        paras = [{'params': self.hypernet_params, 'lr': self.lr * self.lrratio},\n",
    "                 {'params': self.model_hyper.res.parameters(), 'lr': self.lr}\n",
    "                 ]\n",
    "        self.solver = torch.optim.Adam(paras, weight_decay=self.weight_decay)\n",
    "\n",
    "        train_loader = DataLoader(config.dataset, config.train_path, train_idx, config.patch_size, config.train_patch_num, batch_size=config.batch_size, istrain=True)\n",
    "        test_loader = DataLoader(config.dataset, config.test_path, test_idx, config.patch_size, config.test_patch_num, istrain=False)\n",
    "        self.train_data = train_loader.get_data()\n",
    "        self.test_data = test_loader.get_data()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Training\"\"\"\n",
    "        best_srcc = 0.0\n",
    "        best_plcc = 0.0\n",
    "        print('Epoch\\tTrain_Loss\\tTrain_SRCC\\tTest_SRCC\\tTest_PLCC\\tTest_MAE\\tTest_MSE')\n",
    "        for t in range(self.epochs):\n",
    "            epoch_loss = []\n",
    "            pred_scores = []\n",
    "            gt_scores = []\n",
    "\n",
    "            for img, label in tqdm(self.train_data):\n",
    "                img = torch.tensor(img.to(device))\n",
    "                label = torch.tensor(label.to(device))\n",
    "\n",
    "                self.solver.zero_grad()\n",
    "\n",
    "                # Generate weights for target network\n",
    "                paras = self.model_hyper(img)  # 'paras' contains the network weights conveyed to target network\n",
    "\n",
    "                # Building target network\n",
    "                model_target = models.TargetNet(paras).to(device)\n",
    "                for param in model_target.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "                # Quality prediction\n",
    "                pred = model_target(paras['target_in_vec'])  # while 'paras['target_in_vec']' is the input to target net\n",
    "                pred_scores = pred_scores + pred.cpu().tolist()\n",
    "                gt_scores = gt_scores + label.cpu().tolist()\n",
    "\n",
    "                loss = self.l1_loss(pred.squeeze(), label.float().detach())\n",
    "                epoch_loss.append(loss.item())\n",
    "                loss.backward()\n",
    "                self.solver.step()\n",
    "\n",
    "            train_srcc, _ = stats.spearmanr(pred_scores, gt_scores)\n",
    "\n",
    "            test_srcc, test_plcc, test_mae, test_mse = self.test(self.test_data)\n",
    "            if test_srcc > best_srcc:\n",
    "                best_srcc = test_srcc\n",
    "                best_plcc = test_plcc\n",
    "            \n",
    "            print('%d\\t%4.3f\\t\\t%4.4f\\t\\t%4.4f\\t\\t%4.4f\\t\\t%4.4f\\t\\t%4.4f' %\n",
    "                  (t + 1, sum(epoch_loss) / len(epoch_loss), train_srcc, test_srcc, test_plcc, test_mae, test_mse))\n",
    "\n",
    "            # Update optimizer\n",
    "            lr = self.lr / pow(10, (t // 6))\n",
    "            if t > 8:\n",
    "                self.lrratio = 1\n",
    "            self.paras = [{'params': self.hypernet_params, 'lr': lr * self.lrratio},\n",
    "                          {'params': self.model_hyper.res.parameters(), 'lr': self.lr}\n",
    "                          ]\n",
    "            self.solver = torch.optim.Adam(self.paras, weight_decay=self.weight_decay)\n",
    "\n",
    "        print('Best test SRCC %f, PLCC %f' % (best_srcc, best_plcc))\n",
    "\n",
    "        return best_srcc, best_plcc\n",
    "\n",
    "    def test(self, data):\n",
    "        \"\"\"Testing\"\"\"\n",
    "        self.model_hyper.train(False)\n",
    "        pred_scores = []\n",
    "        gt_scores = []\n",
    "\n",
    "        for img, label in data:\n",
    "            # Data.\n",
    "            img = torch.tensor(img.to(device))\n",
    "            label = torch.tensor(label.to(device))\n",
    "\n",
    "            paras = self.model_hyper(img)\n",
    "            model_target = models.TargetNet(paras).to(device)\n",
    "            model_target.train(False)\n",
    "            pred = model_target(paras['target_in_vec'])\n",
    "\n",
    "            pred_scores.append(float(pred.item()))\n",
    "            gt_scores = gt_scores + label.cpu().tolist()\n",
    "\n",
    "        pred_scores = np.mean(np.reshape(np.array(pred_scores), (-1, self.test_patch_num)), axis=1)\n",
    "        gt_scores = np.mean(np.reshape(np.array(gt_scores), (-1, self.test_patch_num)), axis=1)\n",
    "        test_srcc, _ = stats.spearmanr(pred_scores, gt_scores)\n",
    "        test_plcc, _ = stats.pearsonr(pred_scores, gt_scores)\n",
    "        test_mse = mean_squared_error(pred_scores, gt_scores)\n",
    "        test_mae = mae(pred_scores, gt_scores)\n",
    "\n",
    "        self.model_hyper.train(True)\n",
    "        return test_srcc, test_plcc, test_mae, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "601f115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "class Config:\n",
    "    dataset = 'bid'\n",
    "    train_patch_num = 3\n",
    "    test_patch_num = 3\n",
    "    lr = 2e-5\n",
    "    weight_decay = 5e-4\n",
    "    lr_ratio = 10\n",
    "    batch_size = 8\n",
    "    epochs = 5\n",
    "    patch_size = 224\n",
    "    train_test_num = 10\n",
    "    train_path = '../Data/train/'\n",
    "    test_path = '../Data/test/'\n",
    "    \n",
    "config = Config()\n",
    "config.train_patch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d152fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553e286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15766/817440817.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  srcc_all = np.zeros(config.train_test_num, dtype=np.float)\n",
      "/tmp/ipykernel_15766/817440817.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  plcc_all = np.zeros(config.train_test_num, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing on bid dataset for 10 rounds...\n",
      "Round 1\n",
      "Epoch\tTrain_Loss\tTrain_SRCC\tTest_SRCC\tTest_PLCC\tTest_MAE\tTest_MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/39309 [00:00<?, ?it/s]/tmp/ipykernel_15766/267211773.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n",
      "100%|█████████████████████████████████████████████████████████████| 39309/39309 [3:22:41<00:00,  3.23it/s]\n",
      "/tmp/ipykernel_15766/267211773.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0.643\t\t0.3587\t\t0.4477\t\t0.4518\t\t0.5867\t\t0.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/39309 [00:00<?, ?it/s]/tmp/ipykernel_15766/267211773.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n",
      "100%|█████████████████████████████████████████████████████████████| 39309/39309 [3:02:13<00:00,  3.60it/s]\n",
      "/tmp/ipykernel_15766/267211773.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t0.631\t\t0.3305\t\t0.3936\t\t0.3979\t\t0.6006\t\t0.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/39309 [00:00<?, ?it/s]/tmp/ipykernel_15766/267211773.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n",
      "100%|█████████████████████████████████████████████████████████████| 39309/39309 [3:04:54<00:00,  3.54it/s]\n",
      "/tmp/ipykernel_15766/267211773.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t0.629\t\t0.3259\t\t0.3523\t\t0.3747\t\t0.6046\t\t0.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/39309 [00:00<?, ?it/s]/tmp/ipykernel_15766/267211773.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n",
      "100%|█████████████████████████████████████████████████████████████| 39309/39309 [2:58:51<00:00,  3.66it/s]\n",
      "/tmp/ipykernel_15766/267211773.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t0.627\t\t0.3268\t\t0.3620\t\t0.4276\t\t0.5858\t\t0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/39309 [00:00<?, ?it/s]/tmp/ipykernel_15766/267211773.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n",
      "100%|█████████████████████████████████████████████████████████████| 39309/39309 [2:59:02<00:00,  3.66it/s]\n",
      "/tmp/ipykernel_15766/267211773.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t0.625\t\t0.3317\t\t0.3759\t\t0.4147\t\t0.5889\t\t0.7242\n",
      "Best test SRCC 0.447673, PLCC 0.451837\n",
      "Round 2\n",
      "Epoch\tTrain_Loss\tTrain_SRCC\tTest_SRCC\tTest_PLCC\tTest_MAE\tTest_MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/39309 [00:00<?, ?it/s]/tmp/ipykernel_15766/267211773.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n",
      "100%|█████████████████████████████████████████████████████████████| 39309/39309 [3:07:36<00:00,  3.49it/s]\n",
      "/tmp/ipykernel_15766/267211773.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0.641\t\t0.3541\t\t0.4389\t\t0.3862\t\t0.5992\t\t0.7582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/39309 [00:00<?, ?it/s]/tmp/ipykernel_15766/267211773.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img.to(device))\n",
      "/tmp/ipykernel_15766/267211773.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label.to(device))\n",
      " 80%|████████████████████████████████████████████████▌            | 31304/39309 [2:23:05<33:25,  3.99it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "srcc_all = np.zeros(config.train_test_num, dtype=np.float)\n",
    "plcc_all = np.zeros(config.train_test_num, dtype=np.float)\n",
    "sel_num = list(range(0, 29))\n",
    "print('Training and testing on %s dataset for %d rounds...' % (config.dataset, config.train_test_num))\n",
    "for i in range(config.train_test_num):\n",
    "    print('Round %d' % (i+1))\n",
    "    # Randomly select 80% images for training and the rest for testing\n",
    "    random.shuffle(sel_num)\n",
    "    train_index = sel_num[0:int(round(0.8 * len(sel_num)))]\n",
    "    test_index = sel_num[int(round(0.8 * len(sel_num))):len(sel_num)]\n",
    "\n",
    "    solver = HyperIQASolver(config, ' ', train_index, test_index)\n",
    "    srcc_all[i], plcc_all[i] = solver.train()\n",
    "\n",
    "# print(srcc_all)\n",
    "# print(plcc_all)\n",
    "srcc_med = np.median(srcc_all)\n",
    "plcc_med = np.median(plcc_all)\n",
    "\n",
    "print('Testing median SRCC %4.4f,\\tmedian PLCC %4.4f' % (srcc_med, plcc_med))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72b6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
